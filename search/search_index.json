{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Datachecks","text":"<p>Welcome to the Datachecks Documentation!</p> <p>Let's jump to the Getting Started!</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>You can easily launch this example in just 5 minutes.</p>"},{"location":"getting_started/#installation","title":"Installation","text":""},{"location":"getting_started/#mac-os-and-linux","title":"MAC OS and Linux","text":"<p>Install Datachecks using the pip package manager. Below we are installing the package with the postgres extra, which is required for this example.</p> <pre><code>pip install 'dcs-core[postgres]' -U\n</code></pre>"},{"location":"getting_started/#quick-setup-of-database-test-data","title":"Quick Setup of Database &amp; Test Data","text":"<p>Ignore if you already have a PostgreSql setup</p> Create a SQL file <p>Create a sql file named <code>init.sql</code> with the following contents: init.sql<pre><code>CREATE TABLE IF NOT EXISTS products (\n    id INTEGER PRIMARY KEY,\n    name TEXT,\n    category TEXT,\n    country_code TEXT,\n    price INTEGER\n);\nINSERT INTO products VALUES\n    (1, 'Apple', 'Fruit', 'IN', 100),\n    (2, 'Orange', 'Fruit', 'IN', 80),\n    (3, 'Banana', 'Fruit', 'IN', 50),\n    (4, 'Mango', 'Fruit', 'IN', 150),\n    (5, 'Pineapple', 'Fruit', 'IN', 200),\n    (6, 'Papaya', 'Fruit', 'IN', 100),\n    (7, 'Grapes', 'Fruit', 'IN', 120),\n    (8, 'Strawberry', 'Fruit', 'IN', 300),\n    (9, 'Kiwi', 'Fruit', 'US', 200),\n    (10, 'Watermelon', 'Fruit', 'US', 100);\n</code></pre></p> Postgres Docker Compose file <p>Create a <code>docker-compose.yml</code> for postgres:</p> docker-compose.yaml<pre><code>version: '3'\nservices:\n  dcs-demo-postgres:\n    container_name: dcs-demo-postgres\n    image: postgres\n    environment:\n      POSTGRES_DB: dcs_demo\n      POSTGRES_USER: dbuser\n      POSTGRES_PASSWORD: dbpass\n      PGDATA: /data/postgres\n    volumes:\n      - dcs-demo-postgres:/data/postgres\n      - ./init.sql:/docker-entrypoint-initdb.d/init.sql\n    ports:\n      - \"5431:5432\"\n    networks:\n      - dcs-demo-postgres\n    restart: unless-stopped\n\nnetworks:\n  dcs-demo-postgres:\n    driver: bridge\n\nvolumes:\n  dcs-demo-postgres:\n    driver: local\n</code></pre>"},{"location":"getting_started/#datachecks-configuration-file","title":"Datachecks Configuration File","text":"<p>Create a configuration file <code>dcs_config.yaml</code> with the following contents:</p> dcs_config.yaml<pre><code>data_sources:\n  - name: product_db\n    type: postgres\n    connection:\n      host: 127.0.0.1\n      port: 5431\n      username: dbuser\n      password: dbpass\n      database: dcs_demo\nvalidations for product_db.products:\n  - count_of_products:\n      on: count_rows\n      threshold: \"&gt; 0 &amp; &lt; 1000\"\n  - max_product_price_in_india:\n      on: max(price)\n      where: \"country_code = 'IN'\"\n      threshold: \"&lt; 190\"\n</code></pre>"},{"location":"getting_started/#run-datachecks","title":"Run Datachecks","text":"<p>Datachecks can be run in two ways using the CLI or the Python API.</p>"},{"location":"getting_started/#run-datachecks-in-cli","title":"Run Datachecks in CLI","text":"<pre><code>dcs-core inspect --config-path ./dcs_config.yaml\n</code></pre> <p>While running the above command, you should see the following output:</p> <p></p>"},{"location":"getting_started/#generate-metrics-validation-report","title":"Generate Metrics Validation Report","text":"<p>You can generate a beautiful data quality report with all the metrics with just one command. This html report can be shared with the team.</p> <p><pre><code>dcs-core inspect --config-path ./dcs_config.yaml --html-report\n</code></pre> </p>"},{"location":"getting_started/#run-datachecks-in-python","title":"Run Datachecks in Python","text":"<pre><code>from dcs_core.core import Inspect\n\n\nif __name__ == \"__main__\":\n    inspect = Inspect()\n    inspect.add_configuration_yaml_file(\"dcs_config.yaml\")\n    inspect_output = inspect.run()\n    print(inspect_output.metrics)\n    # User the metrics to send or store somewhere\n    # It can be sent to elk or any time series database\n</code></pre>"},{"location":"configuration/datasource_configuration/","title":"Data Source Configuration","text":"<p>Datachecks will read datasource configuration under the key <code>datasources</code> in the configuration file. User can define multiple datasource in the configuration file under <code>datasources</code> key.</p> <p>For example:</p> <pre><code>data_sources:\n  - name: product_db\n    type: postgres\n    connection:\n      host: 127.0.0.1\n      port: 5421\n      username: !ENV ${DB1_USER}\n      password: !ENV ${DB1_PASS}\n      database: dcs_db\n</code></pre>"},{"location":"configuration/datasource_configuration/#environment-variables","title":"Environment Variables","text":"<p>Datachecks supports environment variables in the configuration file. Environment variables can be used in the configuration file using the syntax <code>!ENV ${ENV_VARIABLE}</code>. For example:</p> <pre><code>data_sources:\n  - name: product_db\n    type: postgres\n    connection:\n      host: !ENV ${DB_HOST}\n</code></pre>"},{"location":"configuration/datasource_configuration/#configuration-details","title":"Configuration Details","text":"Parameter Mandatory Description <code>name</code> The name of the datasource. The name should be unique. <code>type</code> The type of the datasource. Possible values are <code>postgres</code>, <code>opensearch</code> etc. Type of datasource mentioned in each supported datasource documentation <code>connection</code> The connection details of the datasource. The connection details are different for each datasource. The connection details are mentioned in each supported datasource documentation."},{"location":"configuration/metric_configuration/","title":"Metric Configuration","text":"<p>Datachecks will read metrics configuration under the key <code>metrics</code> in the configuration file. User can define multiple metrics in the configuration file under <code>metrics</code> key.</p> <p>For example:</p> <pre><code>validations for mysql_db.table_name:\n  - freshness_example:\n      on: freshness(last_updated)\n      threshold: \"&gt; 86400\" ##Freshness metric value is in seconds. Validation error if metric value is greater than 86400 seconds.\n</code></pre>"},{"location":"configuration/metric_configuration/#configuration-details","title":"Configuration Details","text":"Parameter Mandatory Description <code>&lt;key filed&gt;</code> The name of the validation. The name should be unique. <code>on</code> The type of the validation function. Possible values are <code>freshness</code>, <code>row_count</code> etc. Type of validation mentioned in every metric documentation <code>where</code> The where filter to be applied on the filed. In <code>where</code> field we can pass <code>SQL Query</code>(In ase of SQl DB) or <code>Search Query</code>(In ase of search engine). For example:  <code>where: city = 'bangalore' AND age &gt;= 30</code> <code>threshold</code> The validation will be applied on the validation value. A validation error will be invoked if the metric value violate threshold value.  Possible values for threshold are <code>&gt;</code>, <code>&gt;=</code>, <code>=</code> , <code>&lt;</code>, <code>&lt;=</code>. We can combine multiple operators   For example:  <code>threshold: \"&gt;= 10 &amp; &lt;= 100\"</code>"},{"location":"configuration/metric_configuration/#validation-types","title":"Validation Types","text":"<p>Supported Validation functions are</p> Validation Group Validation Type Reliability Freshness Reliability Row Count Reliability Document Count Numeric Distribution Average Numeric Distribution Minimum Numeric Distribution Maximum Numeric Distribution Sum Numeric Distribution Variance Numeric Distribution Standard Deviation Uniqueness Distinct Count Uniqueness Duplicate Count Completeness Null Count Completeness Null Percentage Completeness Empty Count Completeness Empty Percentage Special Custom SQL Validity Count UUID Validity Percentage UUID"},{"location":"integrations/bigquery/","title":"GCP BigQuery","text":""},{"location":"integrations/bigquery/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[bigquery]\n</code></pre>"},{"location":"integrations/bigquery/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>BigQuery datasource can be defined as below in the config file.</p> <p>The type of the data source must be <code>bigquery</code>.</p> <p>Below is an example of the configuration file.</p> <pre><code>data_sources:\n  - name: bigquery_datasource\n    type: bigquery\n    config:\n      project: &lt;gcp_project_id&gt;\n      dataset: &lt;gcp_dataset_name&gt;\n      credentials_base64: &lt;base64 encoded credentials json&gt;\n</code></pre>"},{"location":"integrations/bigquery/#how-to-create-base64-encoded-credentials-json","title":"How to create base64 encoded credentials json?","text":"<p>To create the base64 encoded string you can use the command line tool <code>base64</code>, or <code>openssl base64</code>, or <code>python -m base64</code></p>"},{"location":"integrations/databricks/","title":"Databricks","text":""},{"location":"integrations/databricks/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[databricks]\n</code></pre>"},{"location":"integrations/databricks/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>Databricks datasource can be defined as below in the config file.</p> <p>The type of the data source must be <code>databricks</code>.</p> <p>Below is an example of the configuration file.</p> <pre><code>data_sources:\n  - name: databricks_datasource\n    type: databricks\n    config:\n      host: \"&lt;&gt;.cloud.databricks.com\"\n      port: 443\n      schema: \"test_schema\"\n      catalog: \"test_catalog\"\n      http_path: \"sql/1.0/warehouses/...\"\n      token: \"36 char token generated in Databricks\"\n</code></pre>"},{"location":"integrations/elasticsearch/","title":"ElasticSearch","text":""},{"location":"integrations/elasticsearch/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[elasticsearch]\n</code></pre>"},{"location":"integrations/elasticsearch/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>ElasticSearch data source can be defined as below in the config file.</p> <p>The type of the data source must be <code>elasticsearch</code>.</p> <p>Below is an example of the configuration file.</p> <pre><code>data_sources:\n  - name: elasticsearch_datasource\n    type: elasticsearch\n    config:\n      host: localhost\n      port: 9200\n      username: admin|optional\n      password: changeme|optional\n</code></pre>"},{"location":"integrations/ibm_db2/","title":"IBM DB2","text":""},{"location":"integrations/ibm_db2/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[db2]\n</code></pre>"},{"location":"integrations/ibm_db2/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>IBM DB2 datasource can be defined as below in the config file.</p> <p>The type of the data source must be <code>db2</code>.</p> <p>Below is an example of the configuration file.</p> <pre><code>data_sources:\n  - name: db2_datasource\n    type: db2\n    connection:\n      host: localhost\n      port: 50000\n      username: username\n      password: password\n      database: bludb\n      security: ssl\n      protocol: TCPIP\n      schema: DCS\n</code></pre>"},{"location":"integrations/mssql/","title":"MS SQL Server","text":""},{"location":"integrations/mssql/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[mssql]\n</code></pre>"},{"location":"integrations/mssql/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>MS SQL Server data source can be defined as below in the config file.</p> <pre><code># config.yaml\ndata_sources:\n  - name: mssql_datasource\n    type: mssql\n    config:\n      host: test.database.windows.net\n      port: 1433\n      username: dbuser\n      password: DBpass123\n      database: test-dcs\n      schema: dbo\n      driver: ODBC Driver 17 for SQL Server\n</code></pre>"},{"location":"integrations/mysql/","title":"Mysql","text":""},{"location":"integrations/mysql/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[mysql]\n</code></pre>"},{"location":"integrations/mysql/#create-a-user","title":"Create a user","text":"<p>As a super-user, please execute the following SQL commands in order to create a new group, assign a user to that group, and grant necessary permissions to access and monitor system tables.</p> <p>Please ensure that a secure password is generated and stored properly as it will be used for adding datasource in configuration file</p> <pre><code>CREATE ROLE dcs_role;\nGRANT REFERENCES ON *.* TO dcs_role;\nGRANT USAGE ON *.* TO dcs_role;\nGRANT SELECT ON *.* TO dcs_role;\n\nCREATE USER dcs_user IDENTIFIED BY 'DBpass123';\n\nGRANT dcs_role to dcs_user WITH ADMIN OPTION;\nSET DEFAULT ROLE dcs_role TO dcs_user;\n</code></pre>"},{"location":"integrations/mysql/#granting-permissions-to-tables-in-a-schema","title":"Granting permissions to tables in a schema","text":"<p>For each schema, execute the following three commands to grant read-only access. Below is the example for granting access to the public schema.</p> <pre><code>-- Grant usage on schema and select on current and future child tables\nGRANT USAGE ON schema_name.* TO dcs_role;\nGRANT SELECT ON schema_name.* TO dcs_role;\nGRANT ALL PRIVILEGES ON schema_name.* TO dcs_role;\n</code></pre>"},{"location":"integrations/mysql/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>Mysql data source can be defined as below in the config file.</p> <pre><code># config.yaml\ndata_sources:\n  - name: mysql_datasource\n    type: mysql\n    config:\n      host: localhost\n      port: 3306\n      user: dbuser\n      password: DBpass123\n      database: dc_db\n</code></pre>"},{"location":"integrations/opensearch/","title":"OpenSearch","text":""},{"location":"integrations/opensearch/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[opensearch]\n</code></pre>"},{"location":"integrations/opensearch/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>OpenSearch data source can be defined as below in the config file.</p> <p>The type of the data source must be <code>opensearch</code>.</p> <p>Below is an example of the configuration file.</p> <pre><code>data_sources:\n  - name: opensearch_datasource\n    type: opensearch\n    config:\n      host: localhost\n      port: 9200\n      username: admin\n      password: changeme\n</code></pre>"},{"location":"integrations/postgres/","title":"PostgreSQL","text":""},{"location":"integrations/postgres/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[postgres]\n</code></pre>"},{"location":"integrations/postgres/#create-a-user","title":"Create a user","text":"<p>As a super-user, please execute the following SQL commands in order to create a new group, assign a user to that group, and grant necessary permissions to access and monitor system tables.</p> <p>Please ensure that a secure password is generated and stored properly as it will be used for adding datasource in configuration file</p> <pre><code>-- Create user and group\nCREATE USER dcs_user WITH PASSWORD 'DBpass123';\n\nCREATE GROUP dcs_group;\n\nALTER GROUP dcs_group ADD USER dcs_user;\n\n-- Grant Postgres' monitor role to the dcs_group\nGRANT pg_monitor TO dcs_group\n</code></pre>"},{"location":"integrations/postgres/#granting-permissions-to-tables-in-a-schema","title":"Granting permissions to tables in a schema","text":"<p>For each schema, execute the following three commands to grant read-only access. Below is the example for granting access to the public schema.</p> <pre><code>-- Grant all permissions to the dcs_group\nGRANT USAGE ON SCHEMA \"public\" TO GROUP dcs_group;\n\nGRANT SELECT ON ALL TABLES IN SCHEMA \"public\" TO GROUP dcs_group;\n\nALTER DEFAULT PRIVILEGES IN SCHEMA \"public\" GRANT SELECT ON TABLES TO GROUP dcs_group;\n</code></pre>"},{"location":"integrations/postgres/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>Postgresql data source can be defined as below in the config file.</p> <pre><code># config.yaml\ndata_sources:\n  - name: postgres_datasource\n    type: postgres\n    config:\n      host: localhost\n      port: 5432\n      user: dbuser\n      password: DBpass123\n      database: postgres\n      schema: public\n</code></pre>"},{"location":"integrations/redshift/","title":"AWS Redshift","text":""},{"location":"integrations/redshift/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[redshift]\n</code></pre>"},{"location":"integrations/redshift/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>AWS Redshift datasource can be defined as below in the config file.</p> <p>The type of the data source must be <code>redshift</code>.</p> <p>Below is an example of the configuration file.</p> <pre><code>data_sources:\n  - name: redshift_datasource\n    type: redshift\n    config:\n      host: &lt;redshift_host&gt;.&lt;region&gt;.redshift.amazonaws.com\n      port: &lt;redshift_port&gt;\n      username: &lt;redshift_username&gt;\n      password: &lt;redshift_password&gt;\n      database: &lt;redshift_database&gt;\n</code></pre>"},{"location":"integrations/snowflake/","title":"GCP BigQuery","text":""},{"location":"integrations/snowflake/#install-dependencies","title":"Install Dependencies","text":"<pre><code>pip install dcs-core[snowflake]\n</code></pre>"},{"location":"integrations/snowflake/#define-datasource-connection-in-configuration-file","title":"Define DataSource Connection in Configuration File","text":"<p>Snowflake datasource can be defined as below in the config file.</p> <p>The type of the data source must be <code>snowflake</code>. Note: Ensure sure that the account follows the correct format for the region. For more information, see Snowflake documentation.</p> <p>Below is an example of the configuration file.</p> <pre><code>data_sources:\n  - name: snowflake_datasource\n    type: snowflake\n    config:\n      account: &lt;snowflake account id&gt;\n      username: &lt;snowflake username&gt;\n      password: &lt;snowflake password&gt;\n      database: &lt;snowflake database name&gt;\n      schema: &lt;snowflake schema name&gt;\n      warehouse: &lt;snowflake warehouse name&gt;\n      role: &lt;snowflake role name&gt;\n</code></pre>"},{"location":"support/contact/","title":"Contact","text":""},{"location":"support/contact/#github","title":"Github","text":"<p>Open an issue on GitHub to report bugs and ask questions.</p>"},{"location":"support/contact/#slack-community","title":"Slack Community","text":"<p>Please join our Slack Channel to chat and connect.</p>"},{"location":"support/contact/#email","title":"Email","text":"<p>Drop a mail at hi@waterdip.ai, and we will get back to you.</p>"},{"location":"support/usage_analytics/","title":"Telemetry","text":""},{"location":"support/usage_analytics/#what-is-telemetry","title":"What is Telemetry?","text":"<p>Telemetry refers to the collection of usage data. We collect some data to understand how many users we have and how they interact with Datachecks. This helps us improve the tool and prioritize implementing the new features. Below we describe what is collected, how to opt out and why we'd appreciate if you keep the telemetry on.</p>"},{"location":"support/usage_analytics/#what-data-is-collected","title":"What data is collected?","text":"<p>Datachecks collects anonymous usage data to help our team improve the tool and to apply development efforts to where our users need them most.</p> <p>We capture one event, when the inspect run is finished. No user data or potentially sensitive information is or ever will be collected. The captured data is limited to:</p> <ul> <li>Operating System and Python version</li> <li>Number of metrics generated</li> <li>Error message, if any, truncated to the first 20 characters.</li> </ul>"},{"location":"support/usage_analytics/#how-to-enabledisable-telemetry","title":"How to enable/disable telemetry?","text":"<p>By default, telemetry is enabled. To disable the data collection you can Set environment variable <code>DISABLE_DCS_ANONYMOUS_TELEMETRY</code> to <code>True</code></p>"},{"location":"support/usage_analytics/#should-i-opt-out","title":"Should I opt out?","text":"<p>Being open-source, we have no visibility into the tool usage unless someone actively reaches out to us or opens a GitHub issue. We\u2019d be grateful if you keep the telemetry on since it helps us answer questions like:</p> <ul> <li>How many people are actively using the tool?</li> <li>Which features are being used most?</li> <li>What is the environment you run Datachecks in?</li> </ul> <p>It helps us prioritize the development of new features and make sure we test the performance in the most popular environments.</p> <p>We understand that you might still prefer not to share any telemetry data, and we respect this wish. Follow the steps above to disable the data collection.</p>"},{"location":"validations/combined/","title":"Combined Metrics","text":"<p>Combined metrics in data quality serve as a cornerstone for ensuring the accuracy and efficiency of your data operations. These metrics provide a holistic view of your data ecosystem, amalgamating various aspects to paint a comprehensive picture.</p> <p>By consistently tracking these combined metrics, you gain invaluable insights into the overall performance of your data infrastructure. This data-driven approach enables you to make informed decisions on optimization, resource allocation, and system enhancements. Moreover, these metrics act as sentinels, promptly detecting anomalies or bottlenecks within your data pipelines. This proactive stance allows you to mitigate potential issues before they escalate, safeguarding the integrity of your data.</p>"},{"location":"validations/combined/#available-function","title":"Available Function","text":"<ul> <li><code>div()</code></li> <li><code>sum()</code></li> <li><code>mul()</code></li> <li><code>sub()</code></li> </ul>"},{"location":"validations/combined/#single-function-expression","title":"Single Function Expression","text":"<p>Example</p> dcs_config.yaml<pre><code>metrics:\n- name: combined_metric_example\n  metric_type: combined\n  expression: sum(count_product_invalid, count_product_valid)\n</code></pre>"},{"location":"validations/combined/#multiple-functions-expression","title":"Multiple Functions Expression","text":"<p>We can combine multiple functions in one expression.</p> <p>Example</p> dcs_config.yaml<pre><code>metrics:\n- name: combined_metric_example\n  metric_type: combined\n  expression: div(sum(count_product_invalid, count_product_valid), count_product)\n</code></pre>"},{"location":"validations/combined/#multiple-functions-expression-with-numeric-values","title":"Multiple Functions Expression with numeric values","text":"<p>We can combine multiple functions in one expression with numeric values.</p> <p>Example</p> dcs_config.yaml<pre><code>metrics:\n- name: combined_metric_example\n  metric_type: combined\n  expression: div(sum(count_product_invalid, 10), count_product)\n</code></pre>"},{"location":"validations/combined/#limitations","title":"Limitations","text":"<p>Combined metrics accepts only 2 arguments in one functions.</p>"},{"location":"validations/completeness/","title":"Completeness Validations","text":"<p>Completeness Validations play a crucial role in data quality assessment, ensuring your datasets are comprehensive and reliable. By regularly monitoring these validations, you can gain profound insights into the extent to which your data captures the entirety of the intended information. This empowers you to make informed decisions about data integrity and take corrective actions when necessary.</p> <p>These Validations unveil potential gaps or missing values in your data, enabling proactive data enhancement. Like a well-oiled machine, tracking completeness validations enhances the overall functionality of your data ecosystem. Just as reliability Validations guarantee up-to-date information, completeness Validations guarantee a holistic, accurate dataset.</p>"},{"location":"validations/completeness/#null-count","title":"Null Count","text":"<p>Null count Validations gauge missing data, a crucial aspect of completeness Validations, revealing gaps and potential data quality issues.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - null count percentage _in_dataset:\n      on: count_null(first_name)\n</code></pre>"},{"location":"validations/completeness/#null-percentage","title":"Null Percentage","text":"<p>Null percentage Validations reveal missing data, a vital facet of completeness Validations, ensuring data sets are whole and reliable.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - empty_string_percentage_in_dataset:\n      on: percent_null(first_name)\n</code></pre>"},{"location":"validations/completeness/#empty-string","title":"Empty String","text":"<p>Empty string Validations gauge the extent of missing or null values, exposing gaps that impact data completeness and reliability.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - empty_string_percentage_in_dataset:\n      on: count_empty_string(first_name)\n</code></pre>"},{"location":"validations/completeness/#empty-string-percentage","title":"Empty String Percentage","text":"<p>Empty String Percentage Validations assess data completeness by measuring the proportion of empty strings in datasets.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - empty_string_percentage_in_dataset:\n      on: percent_empty_string(first_name)\n</code></pre>"},{"location":"validations/custom_sql/","title":"Custom SQL Validation","text":"<p>If the built-in set of validations does not quite give you the information you need from a Validation, you have the flexibility to define your own Validations using <code>custom_sql</code>.</p> <p>The custom SQL Validation empowers you to enter your own completely custom SQL query, providing you with the ability to create much more complex and specify monitors according to your specific requirements. This feature allows you to dig deeper into your data and extract insights that are tailored to your unique needs.</p>"},{"location":"validations/custom_sql/#example","title":"Example","text":"<pre><code>validations for mysql_db.student:\n  - custom_sql_example:\n      on: custom_sql\n      query: |\n        SELECT COUNT(*) FROM student WHERE city = 'bangalore' AND age &gt;= 30\n</code></pre>"},{"location":"validations/numeric_distribution/","title":"Numeric Distribution Validations","text":"<p>Numeric Distribution Validations detect changes in the numeric distribution of values, including outliers, variance, skew and more</p>"},{"location":"validations/numeric_distribution/#average","title":"Average","text":"<p>Average Validations gauge performance in transitional databases and search engines, offering valuable insights into overall effectiveness.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - avg_price:\n      on: avg(price)\n      where: \"country_code = 'IN'\"\n      threshold: \"&lt; 190\"\n</code></pre>"},{"location":"validations/numeric_distribution/#minimum","title":"Minimum","text":"<p>Minimum Validations ensure consistency across transitional databases and search engines, enhancing data quality and retrieval accuracy.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - min_price:\n      on: min(price)\n      threshold: \"&gt; 0\"\n</code></pre>"},{"location":"validations/numeric_distribution/#maximum","title":"Maximum","text":"<p>Maximum Validations gauge the highest values within datasets, helping identify outliers and understand data distribution's upper limits for quality assessment.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - max_price:\n      on: max(price)\n      threshold: \"&lt; 1000\"\n</code></pre>"},{"location":"validations/numeric_distribution/#sum","title":"Sum","text":"<p>Sum Validations measure the total of all values within a dataset, indicating the overall size of a particular dataset to help understand data quality.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - sum_of_price:\n      on: sum(price)\n      threshold: \"&gt; 100 &amp; &lt; 1000\"\n</code></pre>"},{"location":"validations/numeric_distribution/#variance","title":"Variance","text":"<p>Variance in data quality measures the degree of variability or dispersion in a dataset, indicating how spread out the data points are from the mean.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - variance_of_price:\n      on: variance(price)\n      threshold: \"&lt; 2.0\"\n</code></pre>"},{"location":"validations/numeric_distribution/#standard-deviation","title":"Standard Deviation","text":"<p>Standard deviation Validations measure the amount of variation or dispersion of a set of values from the mean, indicating how spread out the data points are from the mean.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - standard_deviation_of_price:\n      on: stddev(price)\n      threshold: \"&lt; .81\"\n</code></pre>"},{"location":"validations/numeric_distribution/#numeric-percentile-validations","title":"Numeric Percentile Validations","text":""},{"location":"validations/numeric_distribution/#20th-percentile","title":"20th Percentile","text":"<p>The 20th Percentile Validation checks the value below which 20% of the data points fall, offering insight into the lower end of the data distribution.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percentile_20_price:\n      on: percentile(price, 20)\n      threshold: \"&gt; 20\"\n</code></pre>"},{"location":"validations/numeric_distribution/#40th-percentile","title":"40th Percentile","text":"<p>The 40th Percentile Validation identifies the value below which 40% of the data points fall, providing insight into the data distribution's lower-middle range.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percentile_40_price:\n      on: percentile(price, 40)\n      threshold: \"&gt; 40\"\n</code></pre>"},{"location":"validations/numeric_distribution/#60th-percentile","title":"60th Percentile","text":"<p>The 60th Percentile Validation checks the value below which 60% of the data points fall, helping understand the distribution of values around the middle of the dataset. Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percentile_60_price:\n      on: percentile(price, 60)\n      threshold: \"&gt; 60\"\n</code></pre>"},{"location":"validations/numeric_distribution/#80th-percentile","title":"80th Percentile","text":"<p>The 80th Percentile Validation examines the value below which 80% of the data points fall, offering insights into the upper-middle range of the dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percentile_80_price:\n      on: percentile(price, 80)\n      threshold: \"&lt; 500\"\n</code></pre>"},{"location":"validations/numeric_distribution/#90th-percentile","title":"90th Percentile","text":"<p>The 90th Percentile Validation identifies the value below which 90% of the data points fall, focusing on the upper range of the dataset.</p> <p>Example Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percentile_90_price:\n      on: percentile(price, 90)\n      threshold: \"&lt; 1000\"\n</code></pre>"},{"location":"validations/reliability/","title":"Reliability Validations","text":"<p>Reliability Validations are an essential tool for ensuring that your tables, indices, or collections are being updated with the most up-to-date and timely data.</p> <p>By consistently monitoring these validations, you can gain better insights into how your systems are performing and make more informed decisions about how to optimize and improve performance. Additionally, these validations can help you identify any potential issues or bottlenecks in your data pipelines, allowing you to take proactive steps to address them before they become major problems.</p> <p>Overall, investing in a reliable and robust set of validations is crucial for maintaining the health and performance of your data applications and ensuring that your systems are running as smoothly and efficiently as possible.</p>"},{"location":"validations/reliability/#freshness","title":"Freshness","text":"<p>Data freshness, also known as data timeliness, refers to the frequency at which data is updated for consumption. It is an important dimension of data quality and a pillar of data observability because recently updated data is more accurate and, therefore, more valuable.</p> <p>In the below example the validation will look for the last updated timestamp of the table or index using <code>updated_at</code> field.</p> <p>The threshold will trigger a validation error when the validation is greater than 86400 seconds</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - freshness_of_products:\n      on: freshness(updated_at)\n      threshold: \"&gt; 86400\"\n</code></pre>"},{"location":"validations/reliability/#row-count","title":"Row Count","text":"<p>The row count validation determines the total number of rows present in a table.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count of products:\n      on: count_rows\n      where: \"country_code = 'IN'\"\n      threshold: \"&gt; 1000\"\n</code></pre>"},{"location":"validations/reliability/#document-count","title":"Document Count","text":"<p>The document count validation determines the total number of documents present in a search data source index.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for search_datastore.product_data_index:\n  - count of documents:\n      on: count_documents\n      threshold: \"&gt; 1000\"\n</code></pre>"},{"location":"validations/uniqueness/","title":"Uniqueness Validations","text":"<p>Uniqueness Validations play a pivotal role in upholding data quality standards. Just as reliability Validations ensure timely data updates, uniqueness Validations focus on the distinctiveness of data entries within a dataset.</p> <p>By consistently tracking these Validations, you gain valuable insights into data duplication, redundancy, and accuracy. This knowledge empowers data professionals to make well-informed decisions about data cleansing and optimization strategies. Uniqueness Validations also serve as a radar for potential data quality issues, enabling proactive intervention to prevent major problems down the line.</p>"},{"location":"validations/uniqueness/#distinct-count","title":"Distinct Count","text":"<p>A distinct count Validation in data quality measures the number of unique values within a dataset, ensuring accuracy and completeness.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - distinct_count_of_product_categories:\n      on: count_distinct(product_category)\n</code></pre>"},{"location":"validations/uniqueness/#duplicate-count","title":"Duplicate Count","text":"<p>Duplicate count is a data quality Validation that measures the number of identical or highly similar records in a dataset, highlighting potential data redundancy or errors.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - distinct count of product categories:\n      on: count_duplicate(product_category)\n</code></pre>"},{"location":"validations/validity/","title":"Validity Validations","text":"<p>Validity checks ensure data is not only correctly formatted but also valid. These metrics are crucial for data quality assurance by verifying adherence to predefined rules and standards. Implementing these checks helps users detect and fix errors, maintaining data integrity and reliability.</p>"},{"location":"validations/validity/#count-uuid","title":"Count UUID","text":"<p>The count UUID validation checks the number of UUIDs in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count uuid for product_id:\n      on: count_uuid(product_id)\n      threshold: \"&gt; 100\"\n</code></pre>"},{"location":"validations/validity/#percentage-uuid","title":"Percentage UUID","text":"<p>The percentage UUID validation checks the percentage of UUIDs in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percentage uuid for product_id:\n      on: percent_uuid(product_id)\n      threshold: \"&gt; 90\"\n</code></pre>"},{"location":"validations/validity/#count-invalid-values","title":"Count Invalid Values","text":"<p>The count invalid values validation checks how many entries in a dataset are invalid according to given values.</p> <p>Example dcs_config.yaml<pre><code>validations for iris_db.iris:\n  - invalid values count for species:\n      on: count_invalid_values(species)\n      values: [\"versicolor\"]\n</code></pre></p>"},{"location":"validations/validity/#percent-invalid-values","title":"Percent Invalid Values","text":"<p>The percent invalid values validation checks the percentage of entries in a dataset that are invalid according to given values.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for iris_db.iris:\n  - invalid values percentage for species:\n      on: percent_invalid_values(species)\n      values: [\"versicolor\"]\n</code></pre>"},{"location":"validations/validity/#count-valid-values","title":"Count Valid Values","text":"<p>The count valid values validation checks how many entries in a dataset are valid according to given values.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for iris_db.iris:\n  - valid values count for species:\n      on: count_valid_values(species)\n      values: [\"setosa\", \"virginica\"]\n</code></pre>"},{"location":"validations/validity/#percent-valid-values","title":"Percent Valid Values","text":"<p>The percent valid values validation checks the percentage of entries in a dataset that are valid according to given values.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for iris_db.iris:\n  - valid values percentage for species:\n      on: percent_valid_values(species)\n      values: [\"setosa\", \"virginica\"]\n      threshold: \"&gt; 65\"\n</code></pre>"},{"location":"validations/validity/#count-invalid-regex","title":"Count Invalid Regex","text":"<p>The count invalid regex validation checks how many entries in a dataset are invalid according to a given regex pattern.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for iris_db.iris:\n  - invalid regex count for species:\n      on: count_invalid_regex(species)\n      pattern: \"^(setosa|virginica)$\"\n</code></pre>"},{"location":"validations/validity/#percent-invalid-regex","title":"Percent Invalid Regex","text":"<p>The percent invalid regex validation checks the percentage of entries in a dataset that are invalid according to a given regex pattern.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for iris_db.iris:\n  - invalid regex percentage for species:\n      on: percent_invalid_regex(species)\n      pattern: \"^(setosa|virginica)$\"\n      threshold: \"&gt; 10\"\n</code></pre>"},{"location":"validations/validity/#count-valid-regex","title":"Count Valid Regex","text":"<p>The count valid regex validation checks how many entries in a dataset are valid according to a given regex pattern.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for iris_db.iris:\n  - valid regex count for species:\n      on: count_valid_regex(species)\n      pattern: \"^(setosa|virginica)$\"\n</code></pre>"},{"location":"validations/validity/#percent-valid-regex","title":"Percent Valid Regex","text":"<p>The percent valid regex validation checks the percentage of entries in a dataset that are valid according to a given regex pattern.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for iris_db.iris:\n  - valid regex percentage for species:\n      on: percent_valid_regex(species)\n      pattern: \"^(setosa|virginica)$\"\n      threshold: \"&gt; 90\"\n</code></pre>"},{"location":"validations/validity/#count-usa-phone-number","title":"Count USA Phone Number","text":"<p>The count USA phone number validation checks the number of valid USA phone numbers in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for customer_db.customers:\n  - count USA phone number for phone_number:\n      on: on: count_usa_phone(usa_phone_number)\n      threshold: \"&gt; 100\"\n</code></pre>"},{"location":"validations/validity/#percentage-usa-phone-number","title":"Percentage USA Phone Number","text":"<p>The percentage USA phone number validation checks the percentage of valid USA phone numbers in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for customer_db.customers:\n  - percentage USA phone number for phone_number:\n      on: percent_usa_phone(usa_phone_number)\n      threshold: \"&gt; 90\"\n</code></pre>"},{"location":"validations/validity/#count-email","title":"Count Email","text":"<p>The count email validation checks the number of valid email addresses in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for customer_db.customers:\n  - count email for email:\n      on: count_email(email)\n</code></pre>"},{"location":"validations/validity/#percentage-email","title":"Percentage Email","text":"<p>The percentage email validation checks the percentage of valid email addresses in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for customer_db.customers:\n  - percentage email for email:\n      on: percent_email(email)\n      threshold: \"&gt; 90\"\n</code></pre>"},{"location":"validations/validity/#string-length-max","title":"String Length Max","text":"<p>The StringLengthMaxValidation checks the maximum length of strings in a specified column.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - product name max length:\n      on: string_length_max(product_name)\n      threshold: \"&lt;= 100\"\n</code></pre>"},{"location":"validations/validity/#string-length-min","title":"String Length Min","text":"<p>The StringLengthMinValidation checks the minimum length of strings in a specified column.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - product name min length:\n      on: string_length_min(product_name)\n      threshold: \"&gt;= 5\"\n</code></pre>"},{"location":"validations/validity/#string-length-average","title":"String Length Average","text":"<p>The StringLengthAverageValidation checks the average length of strings in a specified column.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - product name average length:\n      on: string_length_average(product_name)\n      threshold: \"&gt;= 10\"\n</code></pre>"},{"location":"validations/validity/#geolocation-validations","title":"Geolocation Validations","text":""},{"location":"validations/validity/#count-latitude","title":"Count Latitude","text":"<p>The <code>CountLatitudeValidation</code> checks the number of non-null and valid latitude values (ranging between -90 and 90) in a specified column.</p> <p>Example</p> <pre><code>validations for location_db.geolocation:\n  - location latitude count:\n      on: count_latitude(latitude_column_name)\n      threshold: \"&gt; 100\"\n</code></pre>"},{"location":"validations/validity/#percent-latitude","title":"Percent Latitude","text":"<p>The <code>PercentLatitudeValidation</code> checks the percentage of non-null and valid latitude values (ranging between -90 and 90) in a specified column.</p> <p>Example</p> <pre><code>validations for location_db.geolocation:\n  - location latitude percentage:\n      on: percent_latitude(latitude_column_name)\n      threshold: \"&gt; 80\"\n</code></pre>"},{"location":"validations/validity/#count-longitude","title":"Count Longitude","text":"<p>The <code>CountLongitudeValidation</code> checks the number of non-null and valid longitude values (ranging between -180 and 180) in a specified column.</p> <p>Example</p> <pre><code>validations for location_db.geolocation:\n  - location longitude count:\n      on: count_longitude(longitude_column_name)\n      threshold: \"&gt; 100\"\n</code></pre>"},{"location":"validations/validity/#percent-longitude","title":"Percent Longitude","text":"<p>The <code>PercentLongitudeValidation</code> checks the percentage of non-null and valid longitude values (ranging between -180 and 180) in a specified column.</p> <p>Example</p> <pre><code>validations for location_db.geolocation:\n  - location longitude percentage:\n      on: percent_longitude(longitude_column_name)\n      threshold: \"&gt; 80\"\n</code></pre>"},{"location":"validations/validity/#count-ssn","title":"Count SSN","text":"<p>The count ssn validation checks the number of valid ssn(social security number) in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count ssn of users:\n     on: count_ssn(ssn_number)\n</code></pre>"},{"location":"validations/validity/#percent-ssn","title":"Percent SSN","text":"<p>The percent ssn validation checks the percentage of valid ssn(social security number) in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_ssn_of_user:\n      on: percent_ssn(ssn_number)\n</code></pre>"},{"location":"validations/validity/#count-sedol","title":"Count SEDOL","text":"<p>The count sedol validation checks the number of valid sedol in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count sedol of users:\n     on: count_sedol(sedol_number)\n</code></pre>"},{"location":"validations/validity/#percent-sedol","title":"Percent SEDOL","text":"<p>The percent sedol validation checks the percentage of valid sedol in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_sedol_of_user:\n      on: percent_sedol(sedol_number)\n</code></pre>"},{"location":"validations/validity/#count-cusip","title":"Count CUSIP","text":"<p>The count cusip validation checks the number of valid cusip in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count cusip of users:\n     on: count_cusip(cusip_number)\n</code></pre>"},{"location":"validations/validity/#percent-cusip","title":"Percent CUSIP","text":"<p>The percent cusip validation checks the percentage of valid cusip in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_cusip_of_user:\n      on: percent_cusip(cusip_number)\n</code></pre>"},{"location":"validations/validity/#count-lei","title":"Count LEI","text":"<p>The count lei validation checks the number of valid lei in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count lei of users:\n     on: count_lei(lei_number)\n</code></pre>"},{"location":"validations/validity/#percent-lei","title":"Percent LEI","text":"<p>The percent lei validation checks the percentage of valid lei in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_lei_of_user:\n      on: percent_lei(lei_number)\n</code></pre>"},{"location":"validations/validity/#count-figi","title":"Count FIGI","text":"<p>The count figi validation checks the number of valid figi in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count figi of users:\n     on: count_figi(figi_number)\n</code></pre>"},{"location":"validations/validity/#percent-figi","title":"Percent FIGI","text":"<p>The percent figi validation checks the percentage of valid figi in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_figi_of_user:\n      on: percent_figi(figi_number)\n</code></pre>"},{"location":"validations/validity/#count-isin","title":"Count ISIN","text":"<p>The count isin validation checks the number of valid isin in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count isin of users:\n     on: count_isin(isin_number)\n</code></pre>"},{"location":"validations/validity/#percent-isin","title":"Percent ISIN","text":"<p>The percent isin validation checks the percentage of valid isin in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_isin_of_user:\n      on: percent_isin(isin_number)\n</code></pre>"},{"location":"validations/validity/#count-permid","title":"Count PermID","text":"<p>The count permid validation checks the number of valid permid in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count permid of users:\n     on: count_permid(perm_id)\n</code></pre>"},{"location":"validations/validity/#percent-permid","title":"Percent PermID","text":"<p>The percent permid validation checks the percentage of valid permid in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_permid_of_user:\n      on: percent_permid(perm_id)\n</code></pre>"},{"location":"validations/validity/#zero-value-validations","title":"Zero Value Validations","text":"<p>Zero value validations are used to identify and validate fields that contain zero values, which are important for datasets where zero values might have specific implications, such as indicating missing or invalid data, or representing real-world conditions.</p>"},{"location":"validations/validity/#count_zero","title":"<code>COUNT_ZERO</code>","text":"<p><code>COUNT_ZERO</code> is used to count the number of rows where the specified field contains a zero value. It can be useful for detecting cases where zero might represent missing data or special conditions.</p> <p>Example:</p> <pre><code>validations for product_db.products:\n  - price zero count:\n      on: count_zero(price)\n      threshold: \"&lt; 52\"\n</code></pre>"},{"location":"validations/validity/#percent_zero","title":"<code>PERCENT_ZERO</code>","text":"<p><code>PERCENT_ZERO</code> is used to calculate the percentage of rows where the specified field contains a zero value. This helps assess the proportion of zero values in a column, allowing the user to enforce percentage-based thresholds for data quality.</p> <p>Example:</p> <pre><code>validations for product_db.products:\n  - price zero percent:\n      on: percent_zero(price)\n      threshold: \"&lt; 10\"\n\n# **Numeric Negative Value Validations**\n\nThe Numeric Negative Value Validations detect negative values in numeric fields within a dataset and ensure that they do not exceed or fall below a specified threshold.\n\n## **COUNT_NEGATIVE**\n\nThis validation counts the number of negative values present in a given numeric field.\n\n**Example**\n\n```yaml\nvalidations for product_db.products:\n  - negative value count should be less than 2:\n      on: count_negative(price)\n      threshold: \"&lt; 2\"\n</code></pre>"},{"location":"validations/validity/#percent_negative","title":"PERCENT_NEGATIVE","text":"<p>This validation calculates the percentage of negative values in a numeric field, relative to the total number of records.</p> <p>Example</p> <pre><code>validations for product_db.products:\n  - negative value percentage should be less than 40%:\n      on: percent_negative(price)\n      threshold: \"&lt; 40\"\n</code></pre>"},{"location":"validations/validity/#count_all_space","title":"COUNT_ALL_SPACE","text":"<p>The count all space validation counts columns with all space values in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count_all_space_value:\n      on: count_all_space(space)\n      threshold: = 0\n</code></pre>"},{"location":"validations/validity/#percent_all_space","title":"PERCENT_ALL_SPACE","text":"<p>The percent all space validation checks the percentage of columns with all space value in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_all_space:\n      on: percent_all_space(space)\n</code></pre>"},{"location":"validations/validity/#count_null_keyword","title":"COUNT_NULL_KEYWORD","text":"<p>The count null keyword validation counts the number of null like keyword in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count_null_keyword:\n     on: count_null_keyword(keyword)\n     threshold: &lt;=10\n</code></pre>"},{"location":"validations/validity/#percent_null_keyword","title":"PERCENT_NULL_KEYWORD","text":"<p>The percent null keyword validation checks the percentage of null like keyword in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_null_keyword:\n     on: percent_null_keyword(keyword)\n</code></pre>"},{"location":"validations/validity/#count-timestamp-string","title":"Count Timestamp String","text":"<p>The count timestamp string validation checks the number of valid timestamp string in ISO format in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count_valid_timestamp:\n     on: count_timestamp_string(timestamp)\n</code></pre>"},{"location":"validations/validity/#percent-timestamp-string","title":"Percent Timestamp String","text":"<p>The percent timestamp string validation checks the percentage of valid timestamp string in ISO format in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_valid_timestamp:\n     on: percent_timestamp_string(timestamp)\n</code></pre>"},{"location":"validations/validity/#count-not-in-future","title":"Count Not In Future","text":"<p>The count not in future validation checks the number of valid timestamp string that are not in future in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count_timestamp_not_in_future:\n     on: count_not_in_future(future_timestamp)\n</code></pre>"},{"location":"validations/validity/#percent-not-in-future","title":"Percent Not In Future","text":"<p>The percent date not in future validation checks the percentage of valid timestamp string that are not in future in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_timestamp_not_in_future:\n     on: percent_not_in_future(future_timestamp)\n</code></pre>"},{"location":"validations/validity/#count-date-not-in-future","title":"Count Date Not In Future","text":"<p>The count date not in future validation checks the number of valid timestamp string with date that are not in future in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - count_date_not_in_future:\n     on: count_date_not_in_future(future_timestamp)\n</code></pre>"},{"location":"validations/validity/#percent-date-not-in-future","title":"Percent Date Not In Future","text":"<p>The percent date not in future validation checks the percentage of valid timestamp string with date that are not in future in a dataset.</p> <p>Example</p> dcs_config.yaml<pre><code>validations for product_db.products:\n  - percent_date_not_in_future:\n     on: percent_date_not_in_future(future_timestamp)\n</code></pre>"}]}